{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "920a26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt4all\n",
    "from gpt4all import GPT4All\n",
    "from deep_translator import GoogleTranslator\n",
    "import asyncio\n",
    "import sys\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255bdcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embed4All',\n",
       " 'GPT4All',\n",
       " 'LLModel',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'gpt4all',\n",
       " 'pyllmodel']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gpt4all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77635503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb25ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fca0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b0b4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alaa AI\\Python Projects\\Chatbots\\GPT by me - Ai Voice Translator & Chat\n"
     ]
    }
   ],
   "source": [
    "print(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78bbb041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GPT4All(device = 'gpu' , model_name = \"alaa_ai_model_gptj_v1.6.gguf\" , model_path ='C:/Users/Alaa AI/Python Projects/Chatbots/GPT by me - Ai Voice Translator & Chat/' , allow_download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87f72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92bc7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeddeb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with model.chat_session():\n",
    "#     input_text = \"هل بإمكانك أن تخبرنى عن مرض adhd\"\n",
    "#     input_text = GoogleTranslator(source='auto', target='en').translate(input_text)\n",
    "#     output = model.generate(prompt=input_text, max_tokens =  1000)\n",
    "#     output = GoogleTranslator(source='auto', target = target_lang).translate(output)\n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348791fd-217e-48ed-afde-b8ab372d648d",
   "metadata": {},
   "source": [
    "# Calling Voice Recognition -- Speech To Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a4433-1ec2-45cd-87b1-3109a6784418",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54874cd1-cb47-40bf-afcd-dfd9db8dae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed7c635-790e-43f6-94ac-53eb78dd39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60659aa5-2f1a-4a89-a4cd-1a9f4012b13d",
   "metadata": {},
   "source": [
    "Record Audio Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1b8468-b571-43b8-8100-b331bf1da137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(RECORD_SECONDS, WAVE_OUTPUT_FILENAME):\n",
    "    #--------- SETTING PARAMS FOR OUR AUDIO FILE ------------#\n",
    "    FORMAT = pyaudio.paInt16    # format of wave\n",
    "    CHANNELS = 1                # no. of audio channels\n",
    "    RATE = 44100                # frame rate\n",
    "    CHUNK = 1024                # frames per audio sample\n",
    "    #--------------------------------------------------------#\n",
    "     \n",
    "    # creating PyAudio object\n",
    "    audio = pyaudio.PyAudio()\n",
    "     \n",
    "    # open a new stream for microphone\n",
    "    # It creates a PortAudio Stream Wrapper class object\n",
    "    stream = audio.open(format=FORMAT,channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "    #----------------- start of recording -------------------#\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    # list to save all audio frames\n",
    "    frames = []\n",
    "\n",
    "    for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        # read audio stream from microphone\n",
    "        data = stream.read(CHUNK)\n",
    "        # append audio data to frames list\n",
    "        frames.append(data)\n",
    "\n",
    "    #------------------ end of recording --------------------#   \n",
    "    print(\"Finished recording.\")\n",
    "      \n",
    "    stream.stop_stream()    # stop the stream object\n",
    "    stream.close()          # close the stream object\n",
    "    audio.terminate()       # terminate PortAudio\n",
    "\n",
    "    #------------------ saving audio ------------------------#\n",
    "\n",
    "    # create wave file object\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "\n",
    "    # settings for wave file object\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "\n",
    "    # closing the wave file object\n",
    "    waveFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5e46b-b460-4242-8527-2c9608719b8b",
   "metadata": {},
   "source": [
    "Read Audio Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1018f479-de0a-442c-b06e-91908c75d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(WAVE_FILENAME):\n",
    "    # function to read audio(wav) file\n",
    "    with open(WAVE_FILENAME, 'rb') as f:\n",
    "        audio = f.read()\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81265e-2ee6-4807-9f0a-f74b9ce0fd10",
   "metadata": {},
   "source": [
    "Wit Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ecef62-3e3c-4e6c-8b13-2e202673b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wit speech API endpoint\n",
    "API_ENDPOINT = 'https://api.wit.ai/speech'\n",
    "\n",
    "# Wit.ai api access token\n",
    "wit_access_token = 'S7JQYY2RA7ABGIFCOWGTUE6RDJSWHNF7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aaf202-0830-4b00-9d34-72885a8045c1",
   "metadata": {},
   "source": [
    "Recognize Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c584bafc-9b74-4da0-b1db-eee24b2d60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a4848fc-4724-4c5d-aadc-bf5665fe7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecognizeSpeech(AUDIO_FILENAME, num_seconds = 5):\n",
    "    \n",
    "    # record audio of specified length in specified audio file\n",
    "    record_audio(num_seconds, AUDIO_FILENAME)\n",
    "    \n",
    "    # reading audio\n",
    "    audio = read_audio(AUDIO_FILENAME)\n",
    "    \n",
    "    # defining headers for HTTP request\n",
    "    headers = {'authorization': 'Bearer ' + wit_access_token,\n",
    "               'Content-Type': 'audio/wav'}\n",
    "\n",
    "    # making an HTTP post request\n",
    "    resp = requests.post(API_ENDPOINT, headers = headers,\n",
    "                         data = audio)\n",
    "    \n",
    "    # converting response content to JSON format\n",
    "    \n",
    "    data = json.loads(json.dumps(resp.text))\n",
    "    data_text = str(data).splitlines()[-3].split(':')\n",
    "    print(data_text[1])\n",
    "    text = data_text[1]\n",
    "#     print(data)\n",
    "    # get text from data\n",
    "#     text = data['text']\n",
    "#     print(\"\\nYou said: {}\".format(text))\n",
    "    # return the text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff622a9f",
   "metadata": {},
   "source": [
    "# Calling functions of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaac5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def response4(g4a):\n",
    "    # a better way to use an executor:\n",
    "    with g4a.chat_session():\n",
    "        # is_message_ended = True\n",
    "        # while is_message_ended == True:\n",
    "        print(\"\\n\")\n",
    "        prompt =  RecognizeSpeech('myspeech.wav', 10) + \"translate to\" + target_lang\n",
    "        # prompt = prompt.replace(\"\\\"\", \"\") \n",
    "        # prompt = prompt.replace(\",\", \"\") \n",
    "        # if('See you' in prompt):\n",
    "        #     break\n",
    "        print(\"\\nAlaa's robot:\")\n",
    "        generator = g4a.generate(prompt, max_tokens = 1000 , streaming = True)\n",
    "        event_loop = asyncio.get_running_loop()\n",
    "        has_tokens = True\n",
    "\n",
    "        def consume(generator):\n",
    "            nonlocal has_tokens\n",
    "            try:\n",
    "                return next(generator)\n",
    "            except StopIteration:\n",
    "                has_tokens = False\n",
    "\n",
    "        while has_tokens:\n",
    "            token = await event_loop.run_in_executor(None, consume, generator)\n",
    "            if token is not None:\n",
    "                yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ed39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_in_arabic(g4a):\n",
    "    with g4a.chat_session():\n",
    "        is_message_ended = True\n",
    "        while is_message_ended == True:\n",
    "            print(\"\\n\")\n",
    "            prompt =  RecognizeSpeech('myspeech.wav', 10) + \"translate to\" + target_lang\n",
    "            if(prompt == 'وداعا' or prompt == 'مع السلامة'):\n",
    "                break\n",
    "            input_text = prompt\n",
    "            input_text = GoogleTranslator(source='auto', target='en').translate(input_text)\n",
    "            output = g4a.generate(prompt=input_text, max_tokens =  1000)\n",
    "            output = GoogleTranslator(source='auto', target = target_lang).translate(output)\n",
    "            print(\"\\nAlaa's robot:\" , output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b658e3ff-1a11-46b5-9d1b-a8b8e5dcc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e70afd09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "إذا أردت إنهاء الشات يرجى قول إلى اللقاء\n",
      "\n",
      "\n",
      "Listening...\n",
      "Finished recording.\n",
      " \"حبيبي كل سنة وانت طيب\",\n",
      "\n",
      "Alaa's robot:\n",
      " \"My dear, you are good every year\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(target_lang == 'ar'):\n",
    "    print(\"إذا أردت إنهاء الشات يرجى قول وداعاً او مع السلامة\")\n",
    "    get_response_in_arabic(model)\n",
    "else:\n",
    "    print(\"إذا أردت إنهاء الشات يرجى قول إلى اللقاء\")\n",
    "    async for token in response4(model):\n",
    "        output.append(token)\n",
    "        print(token, end='', flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9be4de4-c0a6-42a6-ac03-0eee4f9dac74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \"',\n",
       " 'My',\n",
       " ' dear',\n",
       " ',',\n",
       " ' you',\n",
       " ' are',\n",
       " ' good',\n",
       " ' every',\n",
       " ' year',\n",
       " '\"',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9a3ae04-e454-47d3-846a-2f1ab84001c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \" My  dear ,  you  are  good  every  year \" \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a0d6a09-8489-4091-b4b4-ec107e32f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj = gTTS(text=\" \".join(output), lang=target_lang, slow=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccd680e0-07a3-4e29-88bc-b5b609a8e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj.save(\"welcome.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92d8d33e-b5c0-4e9f-8878-46b968a3f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing the converted file \n",
    "os.system(\"mpg321 welcome.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5dd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def response_with_system_and_prompt_template(g4a , system_template , prompt_template):\n",
    "    # a better way to use an executor:\n",
    "    with g4a.chat_session(system_template , prompt_template):\n",
    "        is_message_ended = True\n",
    "        while is_message_ended == True:\n",
    "            print(\"\\n\")\n",
    "            prompt =  RecognizeSpeech('myspeech.wav', 10)\n",
    "            if(prompt == 'goodbye' or prompt == 'exit'):\n",
    "                break\n",
    "            print(\"\\nAlaa's robot:\")\n",
    "            generator = g4a.generate(prompt, max_tokens = 1000 , streaming = True)\n",
    "            event_loop = asyncio.get_running_loop()\n",
    "            has_tokens = True\n",
    "    \n",
    "            def consume(generator):\n",
    "                nonlocal has_tokens\n",
    "                try:\n",
    "                    return next(generator)\n",
    "                except StopIteration:\n",
    "                    has_tokens = False\n",
    "    \n",
    "            while has_tokens:\n",
    "                token = await event_loop.run_in_executor(None, consume, generator)\n",
    "                if token is not None:\n",
    "                    yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations.'\n",
    "prompt_template = 'Human: %1\\nASSISTANT: \\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"If you want to exit or end the chat ... Say 'goodbye' or 'exit'\")\n",
    "async for token in response_with_system_and_prompt_template(model , system_template , prompt_template):\n",
    "    print(token, end='', flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacec3ad-a6d7-4d10-a291-9b15ce692721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
